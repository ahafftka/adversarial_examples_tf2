import tensorflow as tf

from adversarial_examples_tf2.defenders.base_defender import BaseDefender


class AdversarialTrainingDefender(BaseDefender):
    """
    Details on adversarial training can be found in 'Explaining and harnessing
        adversarial examples(Goodfellow, 2015)'. It is a simple and effective
        way to improve classifiers' robustness against adversarial examples.
    """

    def __init__(self, classifier, attackers):
        """
        Initialize the defender for adversarial training.

        Args:
            classifier (classifiers.BaseClassifier): the classifier to apply
                adversarial training on.
            attackers: (attackers.BaseAttacker): the attackers used for
                generating the data used for adversarial training.

        """
        if classifier is None:
            raise ValueError(
                'The classifier cannot be None when initializing '
                ' AdversarialTrainingDefender.')

        if not attackers:
            raise ValueError('The attackers argument is required.')

        super(AdversarialTrainingDefender, self).__init__(
            classifier, attackers)

    def generate_adversarial_training_data(self, data):
        """ Generate the dataset used for adversarial training.

        Args:
            data (tf.data.Dataset): the original training data.
                Each element is a (features, label) tuple of Tensors.
                Features shape needs to match the input shape set in self.
                classifier's initializer. For example, for MNIST,
                self.input_shape = (28, 28) and the dataset feature shape needs
                to be (28, 28) and the dataset label shape needs to be ().

        Returns:
            (tf.data.Dataset): the new dataset that's the same format as the
                original dataset, with the features perturbed by some attackers.

        """
        combined_pertubed_dataset = None

        for attacker in self.attackers:
            if combined_pertubed_dataset is None:
                combined_pertubed_dataset = attacker.generate_adversarial_examples_dataset(
                    data)
            else:
                combined_pertubed_dataset = combined_pertubed_dataset.concatenate(
                    attacker.generate_adversarial_examples_dataset(data))

        return combined_pertubed_dataset

    def retrain_on_adversarial_examples(self, data, epoch_num):
        """
        Retrain and update self.classifier by training on adversarial examples
            generated from self.attackers.

        Args:
            data (tf.data.Dataset): the dataset used for adversarial training.
                Each element is a (features, label) tuple of Tensors.
                Features shape needs to match the input shape set in self.
                classifier's initializer. For example, for MNIST,
                self.input_shape = (28, 28) and the dataset feature shape needs
                to be (None, 28, 28) and the dataset label shape needs to be
                (None, ).
            epoch_num (int): the number of epochs used for training on each set
                of perturbed data generated by each attacker.

        Returns:
            The classifier that has been retrained on adversarial inputs.
        """
        combined_pertubed_dataset = self.generate_adversarial_training_data(
            data)
        self.classifier.train(combined_pertubed_dataset, epoch_num)
        return self.classifier
